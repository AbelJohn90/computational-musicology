---
title: "Kanye West"
output: 
  flexdashboard::flex_dashboard:

    storyboard: true
    vertical_layout: scroll
    theme: journal
---

<style>
.chart-stage-flex{
  min-height: 600px;
}

body {
  padding-top: 70px;
  font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif;
  line-height:1.42857143;}
}

.section.sidebar {
  top: 61px;
}

.storyboard-nav .sbframelist ul li.active {
  border-left: 3px solid #1db954;
}


.navbar-inverse .navbar-nav>li>a:hover, .navbar-inverse .navbar-nav>li>a:focus {
    color: #d9d9d9;
    background-color: #7d7d7d;
}


.nav-tabs-custom > .nav-tabs > li > a {
  border-top-color: white;
  border-right-color: white;
  border-left-color: white;
}

.nav-tabs-custom > .nav-tabs > li.active {
  border-top-color: rgba(50, 93, 136, 0.7);
}





.navbar-inverse{
  background-color:#121212;
  border-color:#080808
}

</style>
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(spotifyr)
library(tidyverse)
library(usethis)
library(knitr)
library(plotly)
library(compmus)
```
```{r, include = FALSE}
knitr::opts_chunk$set(echo = FALSE)

Kanye <- get_artist_audio_features("kanye west")
Kanye
by_album <- Kanye %>%
  filter(album_name == "The College Dropout" |
         album_name == "Late Registration" |
         album_name == "Graduation" | 
         album_name == "808s & Heartbreak" |
         album_name == "My Beautiful Dark Twisted Fantasy" |
         album_name == "Yeezus" |
         album_name == "The Life Of Pablo" |
         album_name == "ye" |
         album_name == "JESUS IS KING")

by_album_summary <- Kanye %>%
  filter(album_name == "The College Dropout" |
         album_name == "Late Registration" |
         album_name == "Graduation" | 
         album_name == "808s & Heartbreak" |
         album_name == "My Beautiful Dark Twisted Fantasy" |
         album_name == "Yeezus" |
         album_name == "The Life Of Pablo" |
         album_name == "ye" |
         album_name == "JESUS IS KING") %>%
    group_by(album_name, album_release_year) %>%
    summarize(valence = mean(valence))
        
```
### The Corpus: The emotional rollecoaster that represents the life of Kanye West and the type of music he created. {data-commentary-width=650}

<img src="https://inbeautymoon.com/wp-content/uploads/2020/07/ccelebritieskanye-west-2-1024x683-1-1058x641.jpg" width="100%">
</img>


***
<b>The Corpus</b> <br>
For this course the well known Hip Hop artist Kanye West has been chosen. Beside being active in the music industry, he also works as a fashion designer and a politician. 

He started producing music for mainstream artist to promote his own rapping career. In 2004 he released his first album 'The College Dropout' which jump started his career. Kanye West had a lot of controversial media attention and is known for having manic moments. The sales of his albums have declined since his first album. This Corpus focuses on each album, and tries to find a correlation between the features of the songs and the decline in sales of his albums. We will analyze several periods of his career. 

<b>The College Dropout and Late Registration: 2003-2006</b> <br>
The first album Kanye West produced was called The College Dropout. This album acclaimed triple platinum and was a successful start for Kanye. Just before the second album Late Registration was released he had his first big controversy. At the Concert for Hurricane Relief he called out George Bush by saying that he doesn't care about black people. Also he stormed out the awards because he lost the award for Best New Artist to Gretchen Wilson. This is were you first see that Kanye has struggles with his mental state and that he has manic episodes. Because he sold so many albums, Kanye decided to create a record label called GOOD Music. These first two albums were high in energy and overall happy compared to his later albums. We hope to see some effect from this later on.

<b>Graduation and, 808s and Heartbreak: 2007-2009</b> <br>
In these albums he started to work with electronic music from the eighties. Also his chord progression was inspired by The Rolling Stones. He also started working with big artist like Daft Punk and Kid Cudi. This is were his creative talent in producing was coming to fruition, and his productions were more unique than other Hip Hop artists at the time. After Graduation Kanye had a lot of problems in life which affected the way he makes music. This is something we expect to see in analysing his music around this period.

<b>My Beautiful Dark Twisted Fantasy and Yeezus: 2010-2015</b> <br>
During this period he wanted to focus more on his fashion brand and his family. Everything what happened before really affected him and he wasn't producing as much as he was doing before. Also he had his first child which ofcourse would affect someone in different ways. 

<b>The life of Pablo, Ye and Jesus Is King: 2016-present</b> 
The end of the road. During this peroid he was cancelling tours, having psychologial issues and was even hospitalized because of this. And recently his wife devorced him because of the fact that he is bipolar. Meaning he could go from depressed to manic from time to time making him very unstable.

We would like to see if there can be found any links between his personal life and the way he produces and writes songs. Because he does both things, there could be a strong correlation. 
```{r}
```

### API features from 2003 to 2019 {data-commentary-width=450}


```{r}
M_dif <- Kanye %>%
  filter(album_name == "The College Dropout" |
         album_name == "JESUS IS KING") %>%
  group_by(album_name) %>%
  arrange(desc(album_name)) %>%
    summarize(dan=mean(danceability), 
              ene=mean(energy), 
              lou=mean(loudness),
              spe=mean(speechiness), 
              aco=mean(acousticness), 
              ins=mean(instrumentalness), 
              liv=mean(liveness), 
              val=mean(valence), 
              tem=mean(tempo),
              dansd=sd(danceability), 
              enesd=sd(energy), 
              lousd=sd(loudness), 
              spesd=sd(speechiness), 
              acosd=sd(acousticness), 
              inssd=sd(instrumentalness), 
              livsd=sd(liveness), 
              valsd=sd(valence), 
              temsd=sd(tempo)
              )
MF <- rbind(tail(M_dif, 1), head(M_dif, 1))

plot <- (
  ggplot(MF) 
  + geom_point(aes(x=album_name, y=dan, size=dansd, text=paste("<b>Danceability</b>\nValue:", dan, "\nSD:", dansd), alpha=0.5), col='green') 
  + geom_line(aes(x=album_name, y=dan, group=1, alpha=0.5), col='green')
  + geom_text(aes(x=0.7, y=first(dan), label='Danceability'), col='green')
  
  + geom_segment(aes(x=1, xend=1, y=0, yend=1), col='red', size=20, alpha=0.05)
  + geom_segment(aes(x=2, xend=2, y=0, yend=1), col='blue', size=20, alpha=0.05)
  
  
  + geom_point(aes(x=album_name, y=ene, size=enesd, text=paste("<b>Energy</b>\nValue:", ene, "\nSD:", enesd), alpha=0.5), col='black') 
  + geom_line(aes(x=album_name, y=ene, group=1, alpha=0.5), col='black')
  + geom_text(aes(x=0.7, y=first(ene), label='Energy'), col='black')
  
  + geom_point(aes(x=album_name, y=spe, size=spesd, text=paste("<b>Speechiness</b>\nValue:", spe, "\nSD:", spesd), alpha=0.5), col='blue') 
  + geom_line(aes(x=album_name, y=spe, group=1, alpha=0.5), col='blue')
  + geom_text(aes(x=0.7, y=first(spe), label='Speechiness'), col='blue')
  
  + geom_point(aes(x=album_name, y=aco, size=acosd, text=paste("<b>Acousticness</b>\nValue:", aco, "\nSD:", acosd), alpha=0.5), col='pink') 
  + geom_line(aes(x=album_name, y=aco, group=1, alpha=0.5), col='pink')
  + geom_text(aes(x=0.7, y=first(aco), label='Acousticness'), col='pink')
  
  + geom_point(aes(x=album_name, y=ins, size=inssd, text=paste("<b>Instrumentalness</b>\nValue:", ins, "\nSD:", inssd), alpha=0.5), col='orange') 
  + geom_line(aes(x=album_name, y=ins, group=1, alpha=0.5), col='orange')
  + geom_text(aes(x=0.7, y=first(ins), label='Instrumentalness'), col='orange')
  
  + geom_point(aes(x=album_name, y=liv, size=livsd, text=paste("<b>Liveness</b>\nValue:", liv, "\nSD:", livsd), alpha=0.5), col='purple') 
  + geom_line(aes(x=album_name, y=liv, group=1, alpha=0.5), col='purple')
  + geom_text(aes(x=0.7, y=first(liv), label='Liveness'), col='purple')
  
  + geom_point(aes(x=album_name, y=val, size=valsd, text=paste("<b>Valence</b>\nValue:", val, "\nSD:", valsd), alpha=0.5), col='red') 
  + geom_line(aes(x=album_name, y=val, group=2, alpha=0.5), col='red')
  + geom_text(aes(x=0.7, y=first(val), label='Valence'), col='red')
  
  + xlab('')
  + ylab('Value')
  + theme_light()
  
)
ggplotly(plot, tooltip = c("text"))
```
```{r}
```

***

<b>The features from the Spotify API</b> <br>
To understand what key differences were between Kanye West's early work and his latest work we decided to extract different spotify API features and see if there were any features that stood out. We checked several featuers for the two albums, The College Dropout and Jesus is King. Valence, Energy, Dancibility, Speechiness, Acousticness, Liveness and Instrumentalness. Two interesting trends can be seen in the figure on the left. We see a drastic change in both Valence and Speechiness. 

<b>Valence</b> <br>
The feature <span style='color:red'>Valence</span>, which describes how positive a song is, almost halves during his career. This would mean that his songs started becoming less happy and more angry or sad. We will try to see if there is any way we can correlate between the chords of a song and how happy or sad it is.  

<b>Speechiness</b> <br>
The feature <span style='color:blue'>Speechiness</span> says something about how many spoken words are found in a track. We see a large difference between Kanye's first album and his last album, suggesting that his first focust more on rap. Since the last album falls under the value of 0.33, Spotify thinks this album is non-speech like music.


```{r}
```

### Analyzing the loss in valence of each album{data-commentary-width=350}

```{r}
by_album <- Kanye %>%
  filter(album_name == "The College Dropout" |
         album_name == "Late Registration" |
         album_name == "Graduation" | 
         album_name == "808s & Heartbreak" |
         album_name == "My Beautiful Dark Twisted Fantasy" |
         album_name == "Yeezus" |
         album_name == "The Life Of Pablo" |
         album_name == "ye" |
         album_name == "JESUS IS KING")

by_album_summary <- Kanye %>%
  filter(album_name == "The College Dropout" |
         album_name == "Late Registration" |
         album_name == "Graduation" | 
         album_name == "808s & Heartbreak" |
         album_name == "My Beautiful Dark Twisted Fantasy" |
         album_name == "Yeezus" |
         album_name == "The Life Of Pablo" |
         album_name == "ye" |
         album_name == "JESUS IS KING") %>%
    group_by(album_name, album_release_year) %>%
    summarize(valence = mean(valence))

ggplot(by_album, aes(x = valence)) + 
geom_histogram() + 
facet_wrap(~ album_name, scales='free_y') +
scale_y_continuous(
  limits=c(0,10)
  ) +
  ggtitle("The Valence per track of each album")

ggplot(by_album_summary, aes(x = album_release_year, y = valence, color = album_name)) +
    geom_point() +
    stat_smooth(method = "lm",
        col = "#C42126",
        se = FALSE,
        size = 1) +
        ggtitle("Trend of valence for each album")

        
```
```{r}
```

***

<b>Valence by album from 2003 to 2019</b> <br>
Kanye west produced 9 albums during his career. We used the Spotify API to extract the valence of each track in each album. Valence is a term used in psychology to describe the emotion of a specific event. Here a low valence is correlated to averseness and positive to goodness. The spotify API uses this feature to describe if a song has a negative emotion like fear and anger, or a positive emotion like joy and happiness. 

From the first album The College Dropout (2003) to Jesus is King (2019) we see a decline in the valence. We suspect that this decline in valence correlates with the decline of the sales of his album, but also his personal life. Were Kanye enjoyed his first years as a pop star, right after Graduation he experienced a lot of distress in his life. It looks like he never really recovered from these events.

<b>808s & Heartbreak</b> <br>
This album was created during a period where Kanye experienced a lot of distressing events. The album was coined as the first emo rap genre, where the songs were mostly about heartbreak and sadness. You can see this clearly in the low value of valence. These events happen right after Graduation, which had relative high valence.


```{r}
```

### Analyzing the loss in speechiness of each album{data-commentary-width=350}

```{r}
by_album <- Kanye %>%
  filter(album_name == "The College Dropout" |
         album_name == "Late Registration" |
         album_name == "Graduation" | 
         album_name == "808s & Heartbreak" |
         album_name == "My Beautiful Dark Twisted Fantasy" |
         album_name == "Yeezus" |
         album_name == "The Life Of Pablo" |
         album_name == "ye" |
         album_name == "JESUS IS KING")

by_album_summary <- Kanye %>%
  filter(album_name == "The College Dropout" |
         album_name == "Late Registration" |
         album_name == "Graduation" | 
         album_name == "808s & Heartbreak" |
         album_name == "My Beautiful Dark Twisted Fantasy" |
         album_name == "Yeezus" |
         album_name == "The Life Of Pablo" |
         album_name == "ye" |
         album_name == "JESUS IS KING") %>%
    group_by(album_name, album_release_year) %>%
    summarize(speechiness = mean(speechiness))

ggplot(by_album, aes(x = speechiness)) + 
geom_histogram() + 
facet_wrap(~ album_name, scales='free_y') +
scale_y_continuous(
  limits=c(0,10)
  ) +
  ggtitle("The Speechiness per track of each album")

ggplot(by_album_summary, aes(x = album_release_year, y = speechiness, color = album_name)) +
    geom_point() +
    stat_smooth(method = "lm",
        col = "#C42126",
        se = FALSE,
        size = 1) +
        ggtitle("Trend of speechiness for each album")

        
```

```{r}
```

***

<b>Speechiness by album from 2003 to 2019</b> <br>
When we analyse the evolution of speechiness from 2003 to 2019 we see that while it does have a downward trend, it seems to change drastically every album. We see some sort of sinus wave where it starts out very high, goes down fast and then rises a little. The literature states that Kanye started experimenting more with music productions after the second album. This could be the reason that speechiness drops, cause more of his energy is put into creating the actual track instead of the lyrics.



```{r}
```

### Self Similarity Matrices {data-commentary-width=300}

```{r}

SSM_1 <-
  get_tidy_audio_analysis("4KFY4EEv9CN6ivrzD6vEvg") %>% # Change URI.
  compmus_align(beats, segments) %>%                     # Change `bars`
  select(beats) %>%                                      #   in all three
  unnest(beats) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

SSM_1 %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "") + 
  ggtitle("SMM of Breath in Breath out")

SSM_2 <-
  get_tidy_audio_analysis("454Epa1vrCGFddHXKyC1kb") %>% # Change URI.
  compmus_align(beats, segments) %>%                     # Change `bars`
  select(beats) %>%                                      #   in all three
  unnest(beats) %>%                                      #   of these lines.
  mutate(
    pitches =
      map(segments,
        compmus_summarise, pitches,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  ) %>%
  mutate(
    timbre =
      map(segments,
        compmus_summarise, timbre,
        method = "rms", norm = "euclidean"              # Change summary & norm.
      )
  )

SSM_2 %>%
  compmus_self_similarity(timbre, "cosine") %>% 
  ggplot(
    aes(
      x = xstart + xduration / 2,
      width = xduration,
      y = ystart + yduration / 2,
      height = yduration,
      fill = d
    )
  ) +
  geom_tile() +
  coord_fixed() +
  scale_fill_viridis_c(guide = "none") +
  theme_classic() +
  labs(x = "", y = "") +
  ggtitle("SMM God is")
```

***

<b>SSM Matrix</b> <br>
So we used the data we collected on speechiness and valence, and looked for a track with the most disparity between them. It could be interesting if we see a difference in their self similarity matrices if there is a big difference between the two features. For the first track we used Breath in Breath out and the second is God is. 

<b>SSM: Breath in Breath out</b> <br>
This one is hard to interpet, you see some diagonal lines. But there aren't any clear blocks like the song God is. 

<b>SSM: God is</b> <br>
This track has a pretty nice SMM matrix. We clearly see a homogeneity block in the center and some repetition blocks. Also we can see some novelt blocks, not as clearly as the other two. 


```{r}
```

### Chordogram: Kanye vs The Stones {data-commentary-width=300}

```{r}
circshift <- function(v, n) {if (n == 0) v else c(tail(v, n), head(v, -n))}
                                    
    # C     C#    D     Eb    E     F     F#    G     Ab    A     Bb    B 
major_chord <- 
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    0,    0)
minor_chord <- 
    c(1,    0,    0,    1,    0,    0,    0,    1,    0,    0,    0,    0)
seventh_chord <- 
    c(1,    0,    0,    0,    1,    0,    0,    1,    0,    0,    1,    0)
major_key <- 
    c(6.35, 2.23, 3.48, 2.33, 4.38, 4.09, 2.52, 5.19, 2.39, 3.66, 2.29, 2.88)
minor_key <-
    c(6.33, 2.68, 3.52, 5.38, 2.60, 3.53, 2.54, 4.75, 3.98, 2.69, 3.34, 3.17)
chord_templates <-
    tribble(
        ~name  , ~template,
        'Gb:7'  , circshift(seventh_chord,  6),
        'Gb:maj', circshift(major_chord,    6),
        'Bb:min', circshift(minor_chord,   10),
        'Db:maj', circshift(major_chord,    1),
        'F:min' , circshift(minor_chord,    5),
        'Ab:7'  , circshift(seventh_chord,  8),
        'Ab:maj', circshift(major_chord,    8),
        'C:min' , circshift(minor_chord,    0),
        'Eb:7'  , circshift(seventh_chord,  3),
        'Eb:maj', circshift(major_chord,    3),
        'G:min' , circshift(minor_chord,    7),
        'Bb:7'  , circshift(seventh_chord, 10),
        'Bb:maj', circshift(major_chord,   10),
        'D:min' , circshift(minor_chord,    2),
        'F:7'   , circshift(seventh_chord,  5),
        'F:maj' , circshift(major_chord,    5),
        'A:min' , circshift(minor_chord,    9),
        'C:7'   , circshift(seventh_chord,  0),
        'C:maj' , circshift(major_chord,    0),
        'E:min' , circshift(minor_chord,    4),
        'G:7'   , circshift(seventh_chord,  7),
        'G:maj' , circshift(major_chord,    7),
        'B:min' , circshift(minor_chord,   11),
        'D:7'   , circshift(seventh_chord,  2),
        'D:maj' , circshift(major_chord,    2),
        'F#:min', circshift(minor_chord,    6),
        'A:7'   , circshift(seventh_chord,  9),
        'A:maj' , circshift(major_chord,    9),
        'C#:min', circshift(minor_chord,    1),
        'E:7'   , circshift(seventh_chord,  4),
        'E:maj' , circshift(major_chord,    4),
        'G#:min', circshift(minor_chord,    8),
        'B:7'   , circshift(seventh_chord, 11),
        'B:maj' , circshift(major_chord,   11),
        'D#:min', circshift(minor_chord,    3))
key_templates <-
    tribble(
        ~name    , ~template,
        'Gb:maj', circshift(major_key,  6),
        'Bb:min', circshift(minor_key, 10),
        'Db:maj', circshift(major_key,  1),
        'F:min' , circshift(minor_key,  5),
        'Ab:maj', circshift(major_key,  8),
        'C:min' , circshift(minor_key,  0),
        'Eb:maj', circshift(major_key,  3),
        'G:min' , circshift(minor_key,  7),
        'Bb:maj', circshift(major_key, 10),
        'D:min' , circshift(minor_key,  2),
        'F:maj' , circshift(major_key,  5),
        'A:min' , circshift(minor_key,  9),
        'C:maj' , circshift(major_key,  0),
        'E:min' , circshift(minor_key,  4),
        'G:maj' , circshift(major_key,  7),
        'B:min' , circshift(minor_key, 11),
        'D:maj' , circshift(major_key,  2),
        'F#:min', circshift(minor_key,  6),
        'A:maj' , circshift(major_key,  9),
        'C#:min', circshift(minor_key,  1),
        'E:maj' , circshift(major_key,  4),
        'G#:min', circshift(minor_key,  8),
        'B:maj' , circshift(major_key, 11),
        'D#:min', circshift(minor_key,  3))
BB <- 
  get_tidy_audio_analysis('2MIBAmYwiuGoKUlpq9B9sZ') %>% 
  # change these 3 to adjust the timestamps (beats, bars, sections)
  compmus_align(sections, segments) %>% 
  select(sections) %>% unnest(sections) %>% 
  mutate(
    pitches = 
      map(segments, 
          compmus_summarise, pitches, 
          method = 'mean', norm = 'manhattan'))
BB %>% 
  compmus_match_pitch_template(key_templates, 'euclidean', 'manhattan') %>% 
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
  geom_tile() +
  scale_fill_viridis_c(option = 'A', guide = 'none') +
  theme_minimal() +
  labs(x = 'Time (s)', y = '') +
  ggtitle("Can't Tell Me Nothing")

BB_2 <- 
  get_tidy_audio_analysis('63T7DJ1AFDD6Bn8VzG6JE8') %>% 
  # change these 3 to adjust the timestamps (beats, bars, sections)
  compmus_align(sections, segments) %>% 
  select(sections) %>% unnest(sections) %>% 
  mutate(
    pitches = 
      map(segments, 
          compmus_summarise, pitches, 
          method = 'mean', norm = 'manhattan'))
BB_2 %>% 
  compmus_match_pitch_template(key_templates, 'euclidean', 'manhattan') %>% 
  ggplot(
    aes(x = start + duration / 2, width = duration, y = name, fill = d)) +
  geom_tile() +
  scale_fill_viridis_c(option = 'A', guide = 'none') +
  theme_minimal() +
  labs(x = 'Time (s)', y = '') + 
  ggtitle("Paint It Black")
```

***

<b>Chordogram between Kanye West and The Rolling Stones</b> <br>
The literature about Kanye's career said that he got inspired by The Rolling Stones and started using their chord progressions. So this was a perfect time to test the chordogram. There were a couple of songs that showed similarity, but we chose Paint it Black and Can't Tell me Nothing. We see that both tracks are predominantly in either B major or Bb major. We see with both clear horizontal lines, were Paint it Black has a little more variation. Around 90 seconds there is a short break/bridge which changes to the chord Db major. 

<b>Kanye Chordograms versus his other tracks in the album Graduation</b> <br>
We have seen other tracks of Kanye, depsite not showing it here, we have seen a lot of resemblance in the horizontal lines. We think that this album focuses more on the lyrics. So the music was set more on the background. With the feature speechiness we see that this album has a low speechiness value, although in relation to the music this isn't that clear.

```{r}
```

### Chromogram: The difference between sad and happy songs

```{r}
# construct chroma analysis
CA_CT_1 <- 
    get_tidy_audio_analysis('2gZUPNdnz5Y45eiGxpHGSc') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)
CA_CT_1 %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'euclidean')) %>% 
    compmus_gather_chroma %>% 
      ggplot(aes(x = start + duration / 2, width = duration, y = pitch_class, fill = value)) + 
      geom_tile() +
      labs(x = 'Time (s)', y = NULL, fill = 'hot') + theme_gray()

CA_CT_2 <- 
    get_tidy_audio_analysis('3nAq2hCr1oWsIU54tS98pL') %>% 
    select(segments) %>% unnest(segments) %>% 
    select(start, duration, pitches)
CA_CT_2 %>% 
    mutate(pitches = map(pitches, compmus_normalise, 'euclidean')) %>% 
    compmus_gather_chroma %>% 
      ggplot(aes(x = start + duration / 2, width = duration, y = pitch_class, fill = value)) + 
      geom_tile() +
      labs(x = 'Time (s)', y = NULL, fill = 'hot') + theme_gray() + 
      ggtitle("Power")
```

***

<b>Power and Waves</b> <br>
We checked two songs, Power and Waves. Power is a song where he sings raps as if he is on his peak. The title of the song says it all. In contrast to waves, is seen as a very sad and conflicting song.</b> <br>

<b>Important Positive Valence Chords</b> <br>
G-Major     -> Serious, Magnificent, Fantasy
C           -> Innocently Happy

<b>Important Negative Valence Chords</b> <br>
F-Minor     -> Obscure, Plaintive, Funereal
D-Minor     -> Deep Distress, Existential Angst
C# Minor    -> Despair, Wailing, Weeping

<b>Power: Happy</b> <br>
So we see some chords that are discribed above, that represent his powerful track. The song is also about how he is in this fantasy where he is the star. He feels happy and strong, but also knows it's some sort of illusion. It is nice to see that in the chromogram

<b>Waves: Sad</b> <br>
We see in the chromogram that the chords F, Bb, Db and C are mostly used. These are chords that are mostly present in sad songs, like Rolling in the Deep from Adele. The song is from his last period, were the valence is the lowest. Also if we follow the news things didn't go well with his marriage because his wife couldn't handel Kanye's struggle with his emotions. 

### Conclusion

In conclusion, we can see that during Kanye's life a lot has happened and this had an effect on his productions. Especially during the events after Graduation, were his music totally changed from rather powerful and happy to sad and even emo. He did get his life back in track when he started writing My Beautiful and Dark fantasy, but it still had a lot of self doubt on what he actually was experiencing. Being bipolar can be hard to deal with expecially in your manic phases where you take to big of risks. We have seen a lot of controversies from him, but let's judge the work and not the artist.
